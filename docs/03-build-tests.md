# Build & Tests Automatis√©s - Guide Complet

> **Document de recherche pour le Module 4 du cours DevOps**
> *Formation M2 ESTD - Architecte Web | ForEach Academy | Novembre 2025*

---

## üìã Table des mati√®res

1. [Introduction](#introduction)
2. [Outils de Build](#outils-de-build)
3. [Types de Tests](#types-de-tests)
4. [Frameworks de Test Modernes](#frameworks-de-test-modernes)
5. [Analyse de Code](#analyse-de-code)
6. [M√©triques Logicielles](#m√©triques-logicielles)
7. [Gestion des Artefacts](#gestion-des-artefacts)
8. [Glossaire](#glossaire)
9. [R√©f√©rences](#r√©f√©rences)

---

## Introduction

Le **build** et les **tests automatis√©s** constituent le c≈ìur de la **livraison continue** (Continuous Delivery) dans les pratiques DevOps modernes. Ces processus transforment le code source en artefacts d√©ployables tout en garantissant la qualit√© et la fiabilit√© du logiciel.

### Pourquoi automatiser le build et les tests ?

L'automatisation apporte des b√©n√©fices mesurables :

- **Rapidit√©** : Build reproductible en quelques minutes au lieu d'heures
- **Fiabilit√©** : D√©tection pr√©coce des bugs (shift-left testing)
- **Confiance** : D√©ploiements sans peur gr√¢ce aux tests automatis√©s
- **Productivit√©** : Les d√©veloppeurs se concentrent sur la valeur m√©tier

### Statistiques cl√©s (2024-2025)

Selon le **State of DevOps Report 2024** (DORA/Google Cloud) :

- Les √©quipes performantes d√©ploient **208 fois plus fr√©quemment**
- Leur **lead time** (commit ‚Üí production) est **106 fois plus rapide**
- Le taux d'√©chec des changements est **7 fois plus bas**
- Le **MTTR** (Mean Time To Recovery) est **2 604 fois plus rapide**

**La diff√©rence ?** Des pipelines de build et test automatis√©s robustes.

---

## Outils de Build

### Qu'est-ce qu'un outil de build ?

Un **outil de build** automatise la transformation du code source en un **artefact ex√©cutable** (binaire, package, image Docker, etc.).

**Responsabilit√©s typiques d'un outil de build** :
- Compilation du code source
- R√©solution des d√©pendances
- Ex√©cution des tests
- G√©n√©ration de documentation
- Packaging et cr√©ation d'artefacts
- Optimisation (minification, tree-shaking)

### Build vs Compilation

| Aspect | Compilation | Build |
|--------|-------------|-------|
| **Port√©e** | Code source ‚Üí code machine | Processus complet de cr√©ation d'artefact |
| **√âtapes** | Analyse syntaxique, g√©n√©ration de bytecode | Compilation + tests + packaging + documentation |
| **Outils** | `gcc`, `javac`, `tsc` | Maven, Gradle, npm, bun |
| **Sortie** | Fichiers `.o`, `.class`, `.js` | JAR, WAR, bundle.js, image Docker |

### Timeline des outils de build majeurs

```
1976 ‚îÄ‚îÄ Make (Stuart Feldman, Bell Labs)
        ‚îÇ   "The grandfather of build tools"
        ‚îÇ   Fichiers Makefile, encore utilis√© aujourd'hui
        ‚îÇ
2000 ‚îÄ‚îÄ Apache Ant (James Duncan Davidson, Apache)
        ‚îÇ   Premier outil de build XML pour Java
        ‚îÇ   Remplace les Makefiles complexes
        ‚îÇ
2004 ‚îÄ‚îÄ Apache Maven (Jason van Zyl, Apache)
        ‚îÇ   Convention over configuration
        ‚îÇ   Gestion de d√©pendances centralis√©e (Maven Central)
        ‚îÇ   Cycle de vie standardis√©
        ‚îÇ
2007 ‚îÄ‚îÄ Rake (Jim Weirich)
        ‚îÇ   Make-like pour Ruby
        ‚îÇ   DSL Ruby pour d√©finir les t√¢ches
        ‚îÇ
2012 ‚îÄ‚îÄ Gradle (Hans Dockter, Adam Murdoch)
        ‚îÇ   DSL Groovy/Kotlin
        ‚îÇ   Build incr√©mental et cache distribu√©
        ‚îÇ   Adopt√© par Google pour Android (2013)
        ‚îÇ
2010 ‚îÄ‚îÄ npm (Isaac Z. Schlueter)
        ‚îÇ   Package manager + build tool pour Node.js
        ‚îÇ   Scripts dans package.json
        ‚îÇ   17 millions de packages en 2024
        ‚îÇ
2016 ‚îÄ‚îÄ Yarn (Facebook/Meta)
        ‚îÇ   R√©solution d√©terministe des d√©pendances
        ‚îÇ   yarn.lock pour reproducibilit√©
        ‚îÇ
2017 ‚îÄ‚îÄ pnpm (Zoltan Kochan)
        ‚îÇ   √âconomie d'espace disque (hard links)
        ‚îÇ   Monorepos optimis√©s
        ‚îÇ
2020 ‚îÄ‚îÄ Bun (Jarred Sumner)
        ‚îÇ   Runtime + bundler + package manager
        ‚îÇ   Performance extr√™me (√©crit en Zig)
        ‚îÇ   Compatible npm, 25x plus rapide
        ‚îÇ
2020 ‚îÄ‚îÄ Vite (Evan You, cr√©ateur de Vue.js)
        ‚îÇ   ESM natif, HMR ultra-rapide
        ‚îÇ   esbuild sous le capot
        ‚îÇ   Rollup pour production
        ‚îÇ
2024 ‚îÄ‚îÄ Turbo (Vercel)
        ‚îÇ   Build system incr√©mental pour monorepos
        ‚îÇ   Remote caching
        ‚îÇ   Int√©gration Vercel
```

### Outils de build modernes par √©cosyst√®me

#### JavaScript/TypeScript

**npm** (2010 - 17M+ packages)
```json
{
  "scripts": {
    "build": "tsc && vite build",
    "test": "vitest",
    "lint": "eslint src/"
  }
}
```

**Vite** (2020 - 15M t√©l√©chargements/semaine)
- Dev server ESM natif (d√©marrage instantan√©)
- HMR en < 50ms
- Build optimis√© avec Rollup
- Tree-shaking automatique

**Bun** (2023 - 1M+ utilisateurs)
```bash
# 25x plus rapide que npm install
bun install

# Bundler int√©gr√©
bun build ./index.ts --outdir ./dist
```

#### Java

**Maven** (2004 - 70% des projets Java)
```xml
<build>
  <plugins>
    <plugin>
      <groupId>org.apache.maven.plugins</groupId>
      <artifactId>maven-compiler-plugin</artifactId>
      <version>3.11.0</version>
    </plugin>
  </plugins>
</build>
```

**Gradle** (2012 - Android officiel)
```kotlin
// build.gradle.kts
plugins {
    kotlin("jvm") version "1.9.20"
}

tasks.test {
    useJUnitPlatform()
}
```

#### Python

**pip + setuptools** (2008)
```python
# setup.py
from setuptools import setup

setup(
    name="myapp",
    version="1.0.0",
    install_requires=["fastapi", "pydantic"]
)
```

**Poetry** (2018 - Moderne)
```toml
[tool.poetry]
name = "myapp"
version = "1.0.0"

[tool.poetry.dependencies]
python = "^3.11"
fastapi = "^0.104.0"
```

#### .NET

**MSBuild** (2003 - Officiel Microsoft)
```xml
<Project Sdk="Microsoft.NET.Sdk">
  <PropertyGroup>
    <TargetFramework>net8.0</TargetFramework>
  </PropertyGroup>
</Project>
```

### Artefacts de build

Un **artefact** est le produit final du build, pr√™t √† √™tre d√©ploy√© ou distribu√©.

**Types d'artefacts courants** :

| Type | Format | Exemples |
|------|--------|----------|
| **Binaires compil√©s** | `.exe`, `.dll`, `.so` | Application C++, biblioth√®que native |
| **Archives Java** | `.jar`, `.war`, `.ear` | Spring Boot JAR, application Java EE |
| **Packages npm** | `.tgz` | Package Node.js |
| **Packages Python** | `.whl`, `.tar.gz` | Distribution PyPI |
| **Images Docker** | Image OCI | `myapp:1.2.3` |
| **Bundles JS** | `.js`, `.mjs` | `bundle.min.js` optimis√© |

---

## Types de Tests

### La Pyramide de Tests (Mike Cohn, 2009)

La **pyramide de tests** illustre la r√©partition id√©ale des tests dans une strat√©gie de test efficace :

```
           /\
          /  \
        /  E2E  \    ‚Üê Peu nombreux, lents, co√ªteux
       /________\
      /          \
     / Integration \  ‚Üê Moyennement nombreux
    /______________\
   /                \
  /   Unit Tests     \ ‚Üê Tr√®s nombreux, rapides, peu co√ªteux
 /____________________\
```

**Ratio recommand√©** : 70% Unit / 20% Integration / 10% E2E

### 1. Tests Unitaires

**D√©finition** : Tests d'une **unit√© de code isol√©e** (fonction, m√©thode, classe) sans d√©pendances externes.

**Caract√©ristiques** :
- ‚ö° **Rapides** : millisecondes par test
- üéØ **Isol√©s** : pas de base de donn√©es, API, filesystem
- üîÑ **Reproductibles** : m√™me input ‚Üí m√™me output
- üìä **Nombreux** : des centaines ou milliers

**Exemple (JavaScript/Vitest)** :
```typescript
// sum.ts
export function sum(a: number, b: number): number {
  return a + b;
}

// sum.test.ts
import { describe, it, expect } from 'vitest';
import { sum } from './sum';

describe('sum', () => {
  it('should add two positive numbers', () => {
    expect(sum(2, 3)).toBe(5);
  });

  it('should handle negative numbers', () => {
    expect(sum(-1, 1)).toBe(0);
  });
});
```

**Bonnes pratiques** :
- Pattern **AAA** : Arrange, Act, Assert
- Un concept test√© par test
- Noms de tests descriptifs
- Pas de logique dans les tests

### 2. Tests d'Int√©gration

**D√©finition** : Tests de l'**interaction entre plusieurs composants** (base de donn√©es, API, services).

**Caract√©ristiques** :
- üê¢ **Plus lents** : secondes par test
- üîó **D√©pendances r√©elles** : BDD, Redis, APIs
- üé≠ **Sc√©narios r√©alistes** : flux utilisateur complets

**Exemple (Python/pytest + API)** :
```python
# test_api_integration.py
import pytest
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

def test_create_and_get_user():
    # Arrange: Create user via API
    response = client.post(
        "/users",
        json={"name": "Alice", "email": "alice@example.com"}
    )
    assert response.status_code == 201
    user_id = response.json()["id"]

    # Act: Retrieve user
    response = client.get(f"/users/{user_id}")

    # Assert
    assert response.status_code == 200
    assert response.json()["name"] == "Alice"
```

### 3. Tests End-to-End (E2E)

**D√©finition** : Tests du **syst√®me complet** du point de vue utilisateur (navigateur, mobile).

**Caract√©ristiques** :
- üêå **Tr√®s lents** : minutes par sc√©nario
- üí∞ **Co√ªteux** : maintenance, environnements
- üé¨ **R√©alistes** : interactions UI r√©elles

**Exemple (Playwright)** :
```typescript
// e2e/login.spec.ts
import { test, expect } from '@playwright/test';

test('user can login and see dashboard', async ({ page }) => {
  // Navigate to app
  await page.goto('https://app.example.com');

  // Fill login form
  await page.fill('[data-testid="email"]', 'user@test.com');
  await page.fill('[data-testid="password"]', 'password123');
  await page.click('[data-testid="submit"]');

  // Assert redirect and content
  await expect(page).toHaveURL(/.*dashboard/);
  await expect(page.locator('h1')).toContainText('Welcome');
});
```

### Le Troph√©e de Tests (Kent C. Dodds, 2018)

R√©interpr√©tation moderne de la pyramide, mettant l'accent sur les **tests d'int√©gration** :

```
           /\
          /  \
        / E2E  \
       /________\
      /          \
     /            \
    /  Integration \ ‚Üê Le sweet spot (meilleur ROI)
   /________________\
  /                  \
 /   Unit   Static    \
/______________________\
```

**Philosophie** : "Write tests. Not too many. Mostly integration."

---

## Frameworks de Test Modernes (2024-2025)

### JavaScript/TypeScript

#### Vitest (2021 - 6M+ t√©l√©chargements/semaine)

**Pourquoi Vitest ?**
- ‚ö° **10x plus rapide** que Jest (Vite sous le capot)
- üîÑ **HMR pour les tests** : feedback instantan√©
- üéØ **Compatible Jest API** : migration facile
- üì∏ **Snapshot testing** int√©gr√©

```typescript
// vite.config.ts
import { defineConfig } from 'vitest/config';

export default defineConfig({
  test: {
    globals: true,
    environment: 'jsdom',
    coverage: {
      reporter: ['text', 'json', 'html'],
      threshold: {
        lines: 80,
        functions: 80,
        branches: 75,
        statements: 80
      }
    }
  }
});
```

**Commandes** :
```bash
# Run tests
bun vitest

# Watch mode
bun vitest --watch

# Coverage
bun vitest --coverage
```

#### Playwright (2020 - Microsoft)

**Leader du test E2E** (remplace Selenium/Puppeteer) :
- üåê **Multi-browser** : Chromium, Firefox, WebKit
- üì± **Mobile emulation** : iPhone, Android
- üé• **Traces & vid√©os** : debugging facile
- üîÑ **Auto-wait** : pas de `sleep()` manuels

```typescript
// playwright.config.ts
import { defineConfig, devices } from '@playwright/test';

export default defineConfig({
  testDir: './e2e',
  fullyParallel: true,
  retries: process.env.CI ? 2 : 0,
  workers: process.env.CI ? 1 : undefined,
  reporter: 'html',

  use: {
    trace: 'on-first-retry',
    screenshot: 'only-on-failure',
  },

  projects: [
    { name: 'chromium', use: { ...devices['Desktop Chrome'] } },
    { name: 'firefox', use: { ...devices['Desktop Firefox'] } },
    { name: 'webkit', use: { ...devices['Desktop Safari'] } },
    { name: 'Mobile Chrome', use: { ...devices['Pixel 5'] } },
  ],
});
```

### Python

#### pytest (2004 - 40M+ t√©l√©chargements/mois)

**Le standard Python** :
- üêç **Pythonic** : assertions Python natives
- üîå **Plugins riches** : pytest-django, pytest-asyncio
- üé™ **Fixtures puissantes** : injection de d√©pendances

```python
# conftest.py (fixtures partag√©es)
import pytest
from sqlalchemy import create_engine
from app.database import Base

@pytest.fixture(scope="session")
def db_engine():
    engine = create_engine("sqlite:///:memory:")
    Base.metadata.create_all(engine)
    yield engine
    engine.dispose()

@pytest.fixture
def db_session(db_engine):
    from sqlalchemy.orm import sessionmaker
    Session = sessionmaker(bind=db_engine)
    session = Session()
    yield session
    session.rollback()
    session.close()

# test_user.py
def test_create_user(db_session):
    user = User(name="Bob", email="bob@test.com")
    db_session.add(user)
    db_session.commit()

    assert user.id is not None
    assert user.name == "Bob"
```

**Configuration (pyproject.toml)** :
```toml
[tool.pytest.ini_options]
minversion = "7.0"
addopts = "-ra -q --cov=app --cov-report=html"
testpaths = ["tests"]
python_files = "test_*.py"
python_classes = "Test*"
python_functions = "test_*"
```

### Java

#### JUnit 5 (2017 - Standard Java moderne)

```java
// UserServiceTest.java
import org.junit.jupiter.api.*;
import static org.junit.jupiter.api.Assertions.*;

@DisplayName("User Service Tests")
class UserServiceTest {

    private UserService userService;

    @BeforeEach
    void setUp() {
        userService = new UserService();
    }

    @Test
    @DisplayName("Should create user with valid data")
    void testCreateUser() {
        User user = userService.create("Alice", "alice@test.com");

        assertNotNull(user.getId());
        assertEquals("Alice", user.getName());
        assertTrue(user.isActive());
    }

    @ParameterizedTest
    @ValueSource(strings = {"", "   ", "null"})
    @DisplayName("Should reject invalid names")
    void testInvalidNames(String name) {
        assertThrows(
            ValidationException.class,
            () -> userService.create(name, "test@example.com")
        );
    }
}
```

### .NET

#### xUnit (2007 - Recommand√© par Microsoft)

```csharp
// UserServiceTests.cs
using Xunit;

public class UserServiceTests
{
    [Fact]
    public void CreateUser_ValidData_ReturnsUser()
    {
        // Arrange
        var service = new UserService();

        // Act
        var user = service.Create("Alice", "alice@test.com");

        // Assert
        Assert.NotNull(user.Id);
        Assert.Equal("Alice", user.Name);
    }

    [Theory]
    [InlineData("")]
    [InlineData("   ")]
    [InlineData(null)]
    public void CreateUser_InvalidName_ThrowsException(string name)
    {
        var service = new UserService();

        Assert.Throws<ArgumentException>(
            () => service.Create(name, "test@example.com")
        );
    }
}
```

---

## Analyse de Code

L'**analyse statique de code** d√©tecte les probl√®mes **sans ex√©cuter** le programme.

### Linters

Les **linters** analysent le code source pour d√©tecter :
- Erreurs de syntaxe
- Code non utilis√©
- Violations de conventions
- Bugs potentiels

#### ESLint (JavaScript/TypeScript)

**Le standard JavaScript** (30M+ t√©l√©chargements/semaine) :

```javascript
// .eslintrc.js
module.exports = {
  extends: [
    'eslint:recommended',
    'plugin:@typescript-eslint/recommended',
    'plugin:react/recommended',
    'prettier' // D√©sactive les r√®gles conflictuelles avec Prettier
  ],
  rules: {
    'no-console': 'warn',
    '@typescript-eslint/no-unused-vars': 'error',
    'react/prop-types': 'off' // TypeScript g√®re d√©j√† les types
  }
};
```

#### Pylint (Python)

```python
# .pylintrc
[MASTER]
ignore=migrations,tests

[MESSAGES CONTROL]
disable=C0111  # missing-docstring

[FORMAT]
max-line-length=100
```

### Formatters

Les **formatters** imposent un **style uniforme** automatiquement (pas de d√©bat !).

#### Prettier (JavaScript/TypeScript)

**"An opinionated code formatter"** (20M+ t√©l√©chargements/semaine) :

```json
{
  "semi": true,
  "singleQuote": true,
  "printWidth": 80,
  "trailingComma": "es5",
  "tabWidth": 2
}
```

**Int√©gration CI** :
```bash
# Check formatting
prettier --check "src/**/*.{ts,tsx}"

# Fix automatically
prettier --write "src/**/*.{ts,tsx}"
```

#### Black (Python)

**"The uncompromising Python formatter"** :
```bash
# Format entire project
black .

# Check only
black --check src/
```

### Analyse Statique Avanc√©e

#### SonarQube

**Plateforme compl√®te d'analyse de code** :
- üêõ **Bugs** : null pointers, resource leaks
- üîí **Vuln√©rabilit√©s** : injections SQL, XSS
- üí© **Code smells** : complexit√©, duplication
- üìä **Couverture** : tests et branches

**M√©triques fournies** :
- **Maintenability Rating** : A-E bas√© sur technical debt
- **Reliability Rating** : bugs par milliers de lignes
- **Security Rating** : vuln√©rabilit√©s critiques
- **Duplications** : % de code dupliqu√©

```yaml
# sonar-project.properties
sonar.projectKey=my-project
sonar.sources=src
sonar.tests=tests
sonar.exclusions=**/node_modules/**,**/dist/**
sonar.javascript.lcov.reportPaths=coverage/lcov.info
```

---

## M√©triques Logicielles

### Code Coverage (Couverture de Code)

**D√©finition** : Pourcentage de code **ex√©cut√©** par les tests.

**Types de couverture** :

1. **Line Coverage** : % de lignes ex√©cut√©es
2. **Branch Coverage** : % de branches conditionnelles test√©es
3. **Function Coverage** : % de fonctions appel√©es
4. **Statement Coverage** : % d'instructions ex√©cut√©es

**Exemple de rapport (Vitest)** :
```
-----------------------------|---------|----------|---------|---------|
File                         | % Stmts | % Branch | % Funcs | % Lines |
-----------------------------|---------|----------|---------|---------|
All files                    |   84.21 |    73.33 |   88.88 |   84.21 |
 src/                        |     100 |      100 |     100 |     100 |
  utils.ts                   |     100 |      100 |     100 |     100 |
 src/services/               |   78.57 |    66.66 |   83.33 |   78.57 |
  userService.ts             |   78.57 |    66.66 |   83.33 |   78.57 |
-----------------------------|---------|----------|---------|---------|
```

**Qu'est-ce qu'un bon taux de couverture ?**

| Taux | Interpr√©tation |
|------|----------------|
| < 50% | ‚ö†Ô∏è Critique - tests insuffisants |
| 50-70% | üü° Acceptable - peut mieux faire |
| 70-85% | ‚úÖ Bon - cible recommand√©e |
| 85-95% | üåü Excellent |
| > 95% | ‚ö†Ô∏è Attention - co√ªt/b√©n√©fice discutable |

**Important** : La couverture est un **indicateur**, pas un **objectif** !

> "100% code coverage doesn't mean 100% bug-free" - Martin Fowler

### Complexit√© Cyclomatique

**D√©finition** (Thomas McCabe, 1976) : Nombre de **chemins ind√©pendants** dans le code.

**Calcul** : `M = E - N + 2P`
- E = nombre d'ar√™tes (transitions)
- N = nombre de n≈ìuds (blocs)
- P = nombre de composants connect√©s

**Interpr√©tation** :

| Complexit√© | Risque | Action |
|------------|--------|--------|
| 1-10 | Faible | Code simple, facile √† tester |
| 11-20 | Mod√©r√© | Acceptable, surveiller |
| 21-50 | √âlev√© | Refactoring recommand√© |
| > 50 | Tr√®s √©lev√© | ‚ö†Ô∏è Refactoring urgent |

**Exemple (fonction complexe)** :
```typescript
// Complexit√© cyclomatique = 8 (trop √©lev√© !)
function calculateDiscount(user, amount) {
  if (user.isPremium) {
    if (amount > 1000) {
      return amount * 0.2;
    } else if (amount > 500) {
      return amount * 0.15;
    }
  } else {
    if (amount > 1000) {
      return amount * 0.1;
    } else if (amount > 500) {
      return amount * 0.05;
    }
  }
  return 0;
}

// Refactor√© (complexit√© = 3)
function calculateDiscount(user, amount) {
  const tier = getDiscountTier(user, amount);
  return amount * tier.rate;
}
```

### DORA Metrics (li√©es au testing)

**DORA** = DevOps Research and Assessment (Google Cloud)

Les 4 m√©triques cl√©s :

1. **Deployment Frequency** : Fr√©quence des d√©ploiements
2. **Lead Time for Changes** : Temps commit ‚Üí production
3. **Change Failure Rate** : % de d√©ploiements √©chou√©s
4. **Time to Restore Service** : Temps de r√©cup√©ration apr√®s incident

**Impact des tests sur les DORA metrics** :

| M√©trique | Impact des tests |
|----------|-----------------|
| Deployment Frequency | Tests rapides = d√©ploiements fr√©quents |
| Lead Time | Pipeline optimis√© r√©duit le lead time |
| Change Failure Rate | Tests solides r√©duisent les √©checs |
| Time to Restore | Tests facilitent le rollback rapide |

**Benchmarks 2024** (DORA Report) :

| Niveau | Deployment Freq. | Lead Time | Change Failure | MTTR |
|--------|-----------------|-----------|----------------|------|
| Elite | On-demand (plusieurs fois/jour) | < 1 heure | 0-15% | < 1 heure |
| High | 1x/jour √† 1x/semaine | 1 jour - 1 semaine | 16-30% | < 1 jour |
| Medium | 1x/mois √† 1x/6 mois | 1 semaine - 1 mois | 16-30% | 1 jour - 1 semaine |
| Low | < 1x/6 mois | 1-6 mois | > 30% | > 6 mois |

---

## Gestion des Artefacts

### Qu'est-ce qu'un artefact ?

Un **artefact** est un fichier **immuable** produit par le build, identifi√© par :
- **Nom** : `myapp`
- **Version** : `1.2.3`
- **Checksum** : `sha256:a3b2c1...`

**Propri√©t√©s** :
- ‚úÖ **Reproductible** : m√™me build = m√™me artefact
- ‚úÖ **Versioned** : semver (Semantic Versioning)
- ‚úÖ **Sign√©** : garantie d'int√©grit√© (GPG, cosign)

### Registres d'artefacts publics

#### npm (JavaScript/TypeScript)

**17 millions de packages** (le plus grand registre) :

```bash
# Publish to npm
npm publish

# Install specific version
npm install express@4.18.2
```

**Versioning avec semver** :
```json
{
  "name": "my-package",
  "version": "1.2.3",
  "dependencies": {
    "express": "^4.18.0",  // Compatible avec 4.x
    "lodash": "~4.17.0"    // Compatible avec 4.17.x
  }
}
```

#### PyPI (Python)

**500,000+ packages** :

```bash
# Build wheel
python -m build

# Upload to PyPI
twine upload dist/*

# Install
pip install requests==2.31.0
```

#### Maven Central (Java)

**12 millions d'artefacts** :

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
    <version>3.2.0</version>
</dependency>
```

#### Docker Hub (Images OCI)

**100 millions d'images** :

```bash
# Pull image
docker pull nginx:1.25-alpine

# Push image
docker tag myapp:latest myuser/myapp:1.2.3
docker push myuser/myapp:1.2.3
```

### Registres priv√©s (entreprise)

#### JFrog Artifactory

**Leader du march√©** pour artefacts entreprise :
- üîí **S√©curit√©** : RBAC, scanning de vuln√©rabilit√©s
- üåê **Multi-format** : Maven, npm, Docker, Helm
- üìä **M√©triques** : t√©l√©chargements, usage
- üîÑ **R√©plication** : g√©ographique

#### Nexus Repository

**Alternative open source** (Sonatype) :
- Maven Central official mirror
- Support npm, PyPI, Docker
- OSS version gratuite

#### GitHub Packages

**Int√©gr√© √† GitHub** :
- npm, Maven, NuGet, Docker
- CI/CD avec GitHub Actions
- Gratuit pour public repos

```yaml
# .github/workflows/publish.yml
- name: Publish to GitHub Packages
  run: |
    echo "//npm.pkg.github.com/:_authToken=${{ secrets.GITHUB_TOKEN }}" > ~/.npmrc
    npm publish
```

### Semantic Versioning (semver)

**Format** : `MAJOR.MINOR.PATCH` (ex: `2.4.1`)

```
MAJOR: 2  ‚Üê Breaking changes (incompatibilit√©)
MINOR: 4  ‚Üê Nouvelles fonctionnalit√©s (r√©tro-compatible)
PATCH: 1  ‚Üê Bug fixes (r√©tro-compatible)
```

**Exemples** :
- `1.0.0` ‚Üí `1.0.1` : Bug fix (patch)
- `1.0.1` ‚Üí `1.1.0` : Nouvelle feature (minor)
- `1.1.0` ‚Üí `2.0.0` : Breaking change (major)

**Versions pr√©-release** :
- `1.0.0-alpha.1` : Alpha (instable)
- `1.0.0-beta.2` : Beta (testing)
- `1.0.0-rc.1` : Release Candidate

---

## Glossaire

### Fran√ßais ‚Üí Anglais

| Fran√ßais | Anglais | D√©finition |
|----------|---------|------------|
| **Artefact** | Artifact | Produit final du build (JAR, image Docker) |
| **Couverture de code** | Code coverage | % de code ex√©cut√© par les tests |
| **D√©pendance** | Dependency | Biblioth√®que externe utilis√©e par le projet |
| **Livraison continue** | Continuous Delivery (CD) | Automatisation du d√©ploiement en production |
| **Int√©gration continue** | Continuous Integration (CI) | Tests automatis√©s √† chaque commit |
| **Pipeline** | Pipeline | S√©quence d'√©tapes automatis√©es (build, test, deploy) |
| **Tests de bout en bout** | End-to-End (E2E) tests | Tests du syst√®me complet (UI incluse) |
| **Tests d'int√©gration** | Integration tests | Tests de l'interaction entre composants |
| **Tests unitaires** | Unit tests | Tests d'une fonction/m√©thode isol√©e |

---

## R√©f√©rences

### Articles fondateurs

1. **"The Practical Test Pyramid"** - Martin Fowler (2012)
   - https://martinfowler.com/articles/practical-test-pyramid.html
   - Introduction de la pyramide de tests

2. **"Write tests. Not too many. Mostly integration."** - Kent C. Dodds (2018)
   - https://kentcdodds.com/blog/write-tests
   - Troph√©e de tests et pragmatisme

3. **"A Complexity Measure"** - Thomas J. McCabe (1976)
   - IEEE Transactions on Software Engineering
   - Introduction de la complexit√© cyclomatique

### Rapports annuels

4. **State of DevOps Report 2024** - DORA (Google Cloud)
   - https://dora.dev/research/
   - DORA metrics et benchmarks

5. **State of JS 2024** - Testing tools survey
   - https://stateofjs.com/en-US/libraries/testing/
   - Adoption des frameworks de test JavaScript

### Documentation officielle

6. **Vitest** - https://vitest.dev/
7. **Playwright** - https://playwright.dev/
8. **pytest** - https://docs.pytest.org/
9. **JUnit 5** - https://junit.org/junit5/
10. **SonarQube** - https://docs.sonarqube.org/

### Livres recommand√©s

11. **"Test Driven Development: By Example"** - Kent Beck (2002)
12. **"Growing Object-Oriented Software, Guided by Tests"** - Steve Freeman & Nat Pryce (2009)
13. **"The Art of Unit Testing"** - Roy Osherove (2013)

---

**Document cr√©√© le** : Novembre 2025
**Auteur** : Fabrice Claeys
**Formation** : Cours Initiation DevOps - M2 ESTD Architecte Web
**Institution** : ForEach Academy

---

*Ce document fait partie du Module 4 du cours DevOps. Pour toute question ou correction, contactez l'√©quipe p√©dagogique.*
