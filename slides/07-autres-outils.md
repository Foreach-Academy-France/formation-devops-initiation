---
marp: true
theme: uncover
paginate: true
footer: M2 ESTD - Initiation DevOps | ForEach Academy
style: |
  section {
    font-size: 20px;
    padding: 40px 50px;
  }
  h1 {
    font-size: 36px;
    color: #2563eb;
    margin: 0 0 15px 0;
  }
  h2 {
    font-size: 28px;
    color: #1e40af;
    margin: 0 0 12px 0;
  }
  h3 {
    font-size: 24px;
    color: #3b82f6;
    margin: 0 0 10px 0;
  }
  code {
    font-size: 18px;
    background: #f3f4f6;
    padding: 1px 4px;
    border-radius: 4px;
  }
  pre {
    font-size: 14px;
  }
  .highlight {
    background: linear-gradient(120deg, #fbbf24 0%, #f59e0b 100%);
    padding: 2px 6px;
    border-radius: 4px;
    color: white;
    font-weight: bold;
  }
  .stat {
    font-size: 36px;
    font-weight: bold;
    color: #dc2626;
  }
  table {
    font-size: 16px;
  }
  blockquote {
    border-left: 4px solid #3b82f6;
    padding-left: 15px;
    font-style: italic;
    color: #1e40af;
  }
  ul, ol {
    margin: 10px 0;
  }
  li {
    margin: 5px 0;
  }
---

<!-- _class: lead -->

# Module 07
## Autres Outils DevOps

**Infrastructure as Code â€¢ Kubernetes â€¢ Monitoring**

*M2 ESTD - Initiation DevOps*
ForEach Academy - 2025

---

## ğŸ“‹ Agenda - Module 07 (45min)

### Infrastructure as Code (IaC)
- Ansible - Configuration management
- Terraform - Infrastructure provisioning

### Kubernetes
- Introduction Ã  l'orchestration de conteneurs

### Monitoring & ObservabilitÃ©
- Prometheus, Grafana, mÃ©triques

### IntÃ©gration DevOps
- Comment tout s'intÃ¨gre

---

<!-- _class: lead -->

# 1. Infrastructure as Code (IaC)

**GÃ©rer l'infrastructure comme du code**

---

## ğŸ¤” Le ProblÃ¨me PrÃ©-IaC

### Configuration Manuelle (AnnÃ©es 2000)

- ğŸ–±ï¸ **ClickOps**: 10-15 clics dans interfaces Web
- âŒ **Configuration drift**: Serveurs devenant incohÃ©rents
- ğŸŒ **Impossible de scaler**: GÃ©rer 100+ serveurs manuellement?
- ğŸ”¥ **"Snowflake servers"**: Chaque serveur unique

> "Works on my machine... but not in production"

---

## âœ¨ Infrastructure as Code - Solution

### Traiter l'Infrastructure comme du Logiciel

```hcl
# Terraform - Infrastructure dÃ©clarative
resource "aws_instance" "web" {
  ami           = "ami-12345678"
  instance_type = "t2.micro"

  tags = {
    Name = "WebServer"
  }
}
```

**Avantages**: Version contrÃ´le â€¢ RÃ©pÃ©tabilitÃ© â€¢ Collaboration â€¢ Rollback

---

## ğŸ“š Deux CatÃ©gories d'IaC

### Configuration Management
- **RÃ´le**: Configurer serveurs existants
- **Outils**: Ansible, Puppet, Chef
- **Use case**: Installer logiciels, gÃ©rer configs

### Infrastructure Provisioning
- **RÃ´le**: CrÃ©er l'infrastructure cloud
- **Outils**: Terraform, CloudFormation, Pulumi
- **Use case**: VMs, rÃ©seaux, databases

**Pattern commun**: Terraform + Ansible

---

<!-- _class: lead -->

# Ansible
## Configuration Management Agentless

---

## ğŸ¯ Qu'est-ce qu'Ansible?

### Automatisation Open-Source par Red Hat

**Architecture**:
- ğŸš« **Agentless**: Pas d'installation sur serveurs cibles
- ğŸ”Œ **SSH**: Communication via SSH (Linux) ou WinRM (Windows)
- ğŸ“ **YAML**: Playbooks lisibles et dÃ©claratifs
- âš¡ **Push-based**: Changements poussÃ©s Ã  la demande

**Adoption**: Netflix, NASA, Capital One

---

## ğŸ“ Playbook Ansible - Exemple

```yaml
---
- name: Configure web servers
  hosts: webservers
  become: yes  # ExÃ©cuter en tant que root

  tasks:
    - name: Install Nginx
      apt:
        name: nginx
        state: present
        update_cache: yes

    - name: Copy website files
      copy:
        src: ./site/
        dest: /var/www/html/

    - name: Start Nginx
      service:
        name: nginx
        state: started
```

---

## ğŸ—ï¸ Ansible - Concepts ClÃ©s

### Inventory (hosts.ini)
```ini
[webservers]
web1.example.com
web2.example.com

[databases]
db1.example.com
```

### Modules
- **apt/yum**: Gestion packages
- **copy/template**: Fichiers
- **service**: Services systÃ¨me
- **git**: Repos Git

### Idempotence
âœ… RÃ©exÃ©cuter le playbook = mÃªme rÃ©sultat

---

## ğŸŒŸ Ansible Galaxy

### Hub Communautaire de RÃ´les

- ğŸ“¦ **30,000+ rÃ´les** prÃ©-construits
- ğŸš€ **Installation rapide**: `ansible-galaxy install geerlingguy.nginx`
- ğŸ’¼ **Ansible Tower/AWX**: Interface web entreprise

**Example de rÃ´le**:
```bash
ansible-galaxy install geerlingguy.docker
ansible-galaxy install geerlingguy.kubernetes
```

---

<!-- _class: lead -->

# Terraform
## Infrastructure Provisioning Multi-Cloud

---

## ğŸ—ï¸ Terraform par HashiCorp

### IaC DÃ©claratif Multi-Cloud

**CrÃ©Ã©**: 2014
**Providers**: 1000+ (AWS, Azure, GCP, Cloudflare, K8s...)
**Langage**: HCL (HashiCorp Configuration Language)

**Success stories**:
- Netflix: Infrastructure AWS complÃ¨te
- Spotify: Multi-cloud deployment
- Uber: Gestion globale infrastructure

---

## ğŸ“– HCL - HashiCorp Configuration Language

```hcl
# DÃ©finition de variable
variable "aws_region" {
  description = "RÃ©gion AWS pour ressources"
  type        = string
  default     = "us-west-2"
}

# Configuration provider
provider "aws" {
  region = var.aws_region
}

# Ressource
resource "aws_vpc" "main" {
  cidr_block = "10.0.0.0/16"

  tags = {
    Name = "main-vpc"
  }
}
```

---

## ğŸ”„ Workflow Terraform

### 4 Commandes Essentielles

```bash
# 1. Initialiser (tÃ©lÃ©charger providers)
terraform init

# 2. Planifier (prÃ©visualiser changements)
terraform plan

# 3. Appliquer (crÃ©er infrastructure)
terraform apply

# 4. DÃ©truire (supprimer infrastructure)
terraform destroy
```

**Workflow**: Init â†’ Plan â†’ Review â†’ Apply

---

## ğŸ’¾ State File - Le Cerveau de Terraform

### terraform.tfstate

- ğŸ“Š **JSON** tracking Ã©tat infrastructure
- ğŸ”— **Mapping** ressources rÃ©elles â†” configuration
- âš ï¸ **Sensible**: Contient secrets, IPs, identifiants

### Remote State (Obligatoire Ã‰quipes)

```hcl
terraform {
  backend "s3" {
    bucket  = "terraform-state"
    key     = "prod/terraform.tfstate"
    region  = "us-west-2"
    encrypt = true
  }
}
```

**Avantages**: Collaboration â€¢ Locking â€¢ SÃ©curitÃ©

---

## ğŸ“¦ Modules Terraform

### Composants RÃ©utilisables (DRY)

```hcl
module "vpc" {
  source = "terraform-aws-modules/vpc/aws"
  version = "5.0.0"

  name = "production-vpc"
  cidr = "10.0.0.0/16"

  azs             = ["us-west-2a", "us-west-2b"]
  private_subnets = ["10.0.1.0/24", "10.0.2.0/24"]
  public_subnets  = ["10.0.101.0/24", "10.0.102.0/24"]

  enable_nat_gateway = true
}
```

**Registry**: registry.terraform.io

---

## âš–ï¸ Terraform vs CloudFormation vs Pulumi

| Feature | **Terraform** | **CloudFormation** | **Pulumi** |
|---------|--------------|-------------------|------------|
| **Multi-cloud** | âœ… Oui (1000+) | âŒ AWS uniquement | âœ… Oui |
| **Langage** | HCL | YAML/JSON | Python, TS, Go |
| **Ã‰tat** | Manuel/Cloud | AWS-gÃ©rÃ© | Manuel/Cloud |
| **CommunautÃ©** | ğŸ”¥ TrÃ¨s large | AWS-focused | ğŸ“ˆ Croissance |
| **Learning Curve** | Moyenne | Ã‰levÃ©e | Facile (devs) |

**Recommandation**: Terraform pour multi-cloud entreprise

---

## ğŸ¯ Ansible + Terraform = â¤ï¸

### Pattern ComplÃ©mentaire

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TERRAFORM         â”‚
â”‚  (Provisioning)     â”‚
â”‚  - CrÃ©er VMs        â”‚
â”‚  - CrÃ©er VPC/rÃ©seauxâ”‚
â”‚  - CrÃ©er databases  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     ANSIBLE         â”‚
â”‚  (Configuration)    â”‚
â”‚  - Installer apps   â”‚
â”‚  - Configurer       â”‚
â”‚  - DÃ©ployer code    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Workflow**: Terraform crÃ©e â†’ Ansible configure

---

<!-- _class: lead -->

# Kubernetes
## Orchestration de Conteneurs

---

## ğŸ¤” Pourquoi l'Orchestration?

### Docker Compose â‰  Production

**ProblÃ¨mes Ã  Ã‰chelle**:
- ğŸ–¥ï¸ **Single host**: Docker Compose = 1 machine
- ğŸ”„ **Pas d'auto-scaling**: Charger â†‘ = Crash
- ğŸ’” **Pas de self-healing**: Conteneur crash = Down
- âš–ï¸ **Pas de load balancing**: Distribution manuelle

**Solution**: Orchestrateur comme Kubernetes

---

## â˜¸ï¸ Kubernetes - Origine

### HÃ©ritage Google Borg

- ğŸ¢ **Google**: 15+ ans d'expÃ©rience avec Borg
- ğŸ“… **2014**: Donation Ã  la CNCF
- ğŸ“ **2018**: CNCF Graduated Project
- ğŸ“Š **2024**: 93% adoption cloud-native

**K8s = Kubernetes** (K + 8 lettres + s)

**ProblÃ¨mes rÃ©solus**:
- Gestion milliers de conteneurs
- Auto-scaling intelligent
- Self-healing automatique
- Zero-downtime deployments

---

## ğŸ›ï¸ Architecture Kubernetes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         CONTROL PLANE (Master)          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ API      â”‚  â”‚ etcd â”‚  â”‚ Scheduler â”‚ â”‚
â”‚  â”‚ Server   â”‚  â”‚      â”‚  â”‚           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    Controller Manager              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                   â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”
â”‚ Worker  â”‚      â”‚ Worker  â”‚
â”‚ Node 1  â”‚      â”‚ Node 2  â”‚
â”‚ Kubelet â”‚      â”‚ Kubelet â”‚
â”‚ Kube-   â”‚      â”‚ Kube-   â”‚
â”‚ proxy   â”‚      â”‚ proxy   â”‚
â”‚ Pods    â”‚      â”‚ Pods    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© Concepts ClÃ©s - Pod

### Plus Petite UnitÃ© DÃ©ployable

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
spec:
  containers:
  - name: nginx
    image: nginx:1.21
    ports:
    - containerPort: 80
```

**CaractÃ©ristiques**:
- ğŸ“¦ 1+ conteneurs partageant rÃ©seau/stockage
- ğŸ†” IP unique dans le cluster
- âš¡ Ã‰phÃ©mÃ¨re (peut Ãªtre dÃ©truit/recrÃ©Ã©)

---

## ğŸš€ Deployment - Gestion de Pods

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3  # 3 copies du Pod
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.21
```

**FonctionnalitÃ©s**: Rolling updates â€¢ Rollback â€¢ Scaling

---

## ğŸŒ Service - Exposition de Pods

### 3 Types Principaux

**ClusterIP** (interne):
```yaml
spec:
  type: ClusterIP  # DÃ©faut
```

**NodePort** (accessible via nÅ“ud):
```yaml
spec:
  type: NodePort
  ports:
  - port: 80
    nodePort: 30007
```

**LoadBalancer** (cloud externe):
```yaml
spec:
  type: LoadBalancer
```

---

## ğŸ“Š K8s vs Docker Compose

| Aspect | **Kubernetes** | **Docker Compose** |
|--------|----------------|-------------------|
| **Ã‰chelle** | Multi-node | Single-host |
| **Auto-scaling** | âœ… HPA, VPA | âŒ |
| **Self-healing** | âœ… Auto-restart | âš ï¸ LimitÃ© |
| **Load Balancing** | âœ… Natif | âŒ Config externe |
| **Rolling Updates** | âœ… Automatique | âŒ Manuel |
| **ComplexitÃ©** | ğŸ”´ Ã‰levÃ©e | ğŸŸ¢ Faible |
| **Use Case** | Production | Dev local |

**RÃ¨gle**: Dev â†’ Compose | Prod â†’ K8s

---

## â˜ï¸ Managed Kubernetes

### Services Cloud

**GKE** (Google):
- Gestion auto control plane
- IntÃ©gration Google Cloud native

**EKS** (AWS):
- Gestion complÃ¨te control plane
- IntÃ©gration IAM/VPC/ALB

**AKS** (Azure):
- Control plane gratuit
- Azure Active Directory

### Local Dev

- **Minikube**: Cluster single-node
- **k3s**: K8s lÃ©ger (<512MB RAM)
- **Kind**: Kubernetes in Docker

---

## ğŸ¯ Cas d'Usage Kubernetes

### Microservices

- ğŸ”€ Isolation des services
- ğŸ“ˆ Scaling indÃ©pendant
- ğŸš€ DÃ©ploiements indÃ©pendants
- ğŸŒ Service mesh (Istio, Linkerd)

### Haute DisponibilitÃ©

- ğŸŒ Multi-zone/rÃ©gion deployments
- ğŸ’š Health checks (liveness, readiness)
- ğŸ”„ Rolling updates zÃ©ro-downtime
- âš–ï¸ Load balancing automatique

### Auto-Scaling

- ğŸ“Š HPA: Horizontal Pod Autoscaler
- ğŸ“ˆ VPA: Vertical Pod Autoscaler
- ğŸ–¥ï¸ Cluster Autoscaler

---

<!-- _class: lead -->

# Monitoring & ObservabilitÃ©
## Observer, Mesurer, AmÃ©liorer

---

## ğŸ‘ï¸ Les 3 Piliers de l'ObservabilitÃ©

### 1. Metrics (MÃ©triques)

Valeurs numÃ©riques au fil du temps
```
http_requests_total{status="200"} 1423
memory_usage_bytes 524288000
```

### 2. Logs (Journaux)

Ã‰vÃ©nements horodatÃ©s
```json
{"level": "ERROR", "message": "DB connection failed"}
```

### 3. Traces (TraÃ§age)

Parcours requÃªte Ã  travers services
```
API Gateway [200ms] â†’ Auth [50ms] â†’ DB [80ms]
```

---

## ğŸ“Š Prometheus - TSDB pour MÃ©triques

### Architecture

**Composants**:
- ğŸ—„ï¸ **Prometheus Server**: Time-Series Database + PromQL
- ğŸ“¤ **Pushgateway**: Jobs Ã©phÃ©mÃ¨res
- ğŸ”” **Alertmanager**: Gestion alertes
- ğŸ“¡ **Exporters**: Exposent mÃ©triques (Node, MySQL...)

**ModÃ¨le Pull**:
- Prometheus scrape targets Ã  intervalles rÃ©guliers
- Targets exposent `/metrics` HTTP endpoint

---

## ğŸ” PromQL - Prometheus Query Language

### RequÃªtes MÃ©triques

```promql
# Taux de requÃªtes HTTP par seconde
rate(http_requests_total[5m])

# Utilisation CPU moyenne
avg(rate(cpu_usage_seconds[1m])) by (instance)

# Percentile 95 de latence
histogram_quantile(0.95,
  rate(http_request_duration_seconds_bucket[5m])
)

# Alertes sur erreurs
sum(rate(http_requests_total{status=~"5.."}[5m])) > 10
```

---

## ğŸ¨ Grafana - Visualisation

### Dashboards Interactifs

**FonctionnalitÃ©s**:
- ğŸ“ˆ 100+ types de panels (graphs, gauges, tables)
- ğŸ”Œ Data sources multiples (Prometheus, Loki, Tempo)
- ğŸ”” Alerting natif
- ğŸ”— Annotations pour Ã©vÃ©nements

**Grafana 2024**:
- Scenes: Dashboards dynamiques
- Explore: Interface unifiÃ©e logs/metrics/traces
- OnCall: Gestion rotation
- SLO Management natif

---

## ğŸ“š Stack LGTM

### Loki, Grafana, Tempo, Mimir

**Grafana Loki** (Logs):
- "Like Prometheus, but for logs"
- Indexe labels uniquement (pas contenu)
- LogQL pour requÃªtes

**Grafana Tempo** (Traces):
- Stockage massif traces
- Compatible OpenTelemetry
- Recherche par Trace ID

**Grafana Mimir** (Metrics):
- Long-term storage Prometheus
- Multi-tenancy, haute disponibilitÃ©

---

## ğŸ¯ SLI, SLO, SLA

### DÃ©finitions

**SLI** (Service Level Indicator):
- MÃ©trique quantitative du service
- Ex: disponibilitÃ©, latence, taux d'erreur

**SLO** (Service Level Objective):
- Cible pour un SLI
- Ex: "99.9% de disponibilitÃ© sur 30 jours"

**SLA** (Service Level Agreement):
- Contrat avec consÃ©quences
- Ex: "99.95% uptime ou remboursement"

---

## ğŸ’° Error Budget

### Budget d'Erreur = 100% - SLO

**Exemple**:
- SLO: 99.9% disponibilitÃ©
- Error budget: 0.1% = 43 min/mois

**Utilisation**:
- Budget consommÃ© â†’ Ralentir dÃ©ploiements
- Budget disponible â†’ Innover rapidement
- âš–ï¸ Balance vitesse/fiabilitÃ©

---

## ğŸ”” Alert Fatigue - Le ProblÃ¨me

### Trop d'Alertes Tue l'Alerte

**Statistiques**:
- ğŸ“§ 2000+ alertes par semaine par Ã©quipe
- âœ… Seulement 3% nÃ©cessitent action immÃ©diate
- ğŸ“‰ 97% sont du bruit
- ğŸ˜´ RÃ©sultat: Alertes ignorÃ©es, vrais incidents manquÃ©s

---

## âœ… Solutions Alert Fatigue

### 1. Alerter sur SymptÃ´mes, pas Causes

```yaml
# âŒ Mauvais
- alert: HighCPU
  expr: cpu_usage > 80%

# âœ… Bon
- alert: SlowResponseTime
  expr: http_request_duration{quantile="0.95"} > 1
  for: 5m
```

### 2. Seuils Dynamiques

```promql
# Ã‰cart de 3 dÃ©viations standard
abs(metric - avg_over_time(metric[1h]))
  > 3 * stddev_over_time(metric[1h])
```

---

## ğŸ¤– Self-Healing Systems

### Auto-RemÃ©diation Kubernetes

**Liveness Probes**:
```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  failureThreshold: 3
```
â†’ RedÃ©marre conteneur si Ã©chec

**HPA** (Horizontal Pod Autoscaler):
```yaml
spec:
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
```
â†’ Scale automatiquement basÃ© sur charge

---

<!-- _class: lead -->

# IntÃ©gration DevOps ComplÃ¨te
## Comment Tout S'IntÃ¨gre

---

## ğŸ”„ Pipeline DevOps Complet

```
Developer Commit
    â†“
GitHub Actions CI
    - Tests, build, scan sÃ©curitÃ©
    â†“
Terraform
    - Provisionne infrastructure (EKS, VPC, RDS)
    â†“
ArgoCD/Flux (GitOps)
    - DÃ©ploie vers Kubernetes
    â†“
Kubernetes
    - Orchestre conteneurs, auto-scale
    â†“
Prometheus + Grafana
    - Collecte mÃ©triques, alerte
    â†“
Feedback Loop
    - Rollback automatique si erreurs
```

---

## ğŸ¯ GitOps - Git comme Source de VÃ©ritÃ©

### Principes

1. **DÃ©claratif**: Ã‰tat dÃ©sirÃ© dans Git
2. **VersionnÃ©**: Historique complet
3. **Auto-sync**: DÃ©tection changements automatique
4. **Auditable**: Qui a changÃ© quoi quand

### Outils

**ArgoCD**: Interface web riche, multi-cluster
**Flux CD**: CLI-driven, Kubernetes-native

---

## ğŸ“Š MÃ©triques DORA

### 4 MÃ©triques ClÃ©s DevOps

1. **Deployment Frequency**: Combien de dÃ©ploiements/jour?
2. **Lead Time**: Temps commit â†’ production
3. **MTTR**: Mean Time To Recovery
4. **Change Failure Rate**: % dÃ©ploiements causant incidents

**Elite performers**:
- Deploy: Plusieurs fois/jour
- Lead time: <1 heure
- MTTR: <1 heure
- Failure rate: <15%

---

## ğŸŒ Ã‰cosystÃ¨me CNCF

### Cloud Native Computing Foundation

**Graduated Projects**:
- â˜¸ï¸ **Kubernetes**: Orchestration
- ğŸ“Š **Prometheus**: Monitoring
- ğŸ”„ **ArgoCD/Flux**: GitOps
- ğŸŒ **Envoy**: Service proxy
- ğŸ”’ **cert-manager**: Certificats TLS

**Landscape**: 1000+ projets
**URL**: landscape.cncf.io

---

## ğŸ“ Gestion Multi-Environnements

### SÃ©paration Dev/Staging/Prod

**Production**:
- ContrÃ´le accÃ¨s strict
- Auto-scaling activÃ©
- Monitoring complet
- Backups automatiques

**Staging**:
- Miroir config production
- DonnÃ©es anonymisÃ©es
- Tests prÃ©-production

**Development**:
- ItÃ©ration rapide
- AccÃ¨s dÃ©veloppeurs
- Ressources optimisÃ©es coÃ»t

---

## ğŸ” Secrets Management

### Ne JAMAIS Hardcoder les Secrets

```yaml
# âŒ Mauvais
env:
  - name: DB_PASSWORD
    value: "password123"

# âœ… Bon
env:
  - name: DB_PASSWORD
    valueFrom:
      secretKeyRef:
        name: db-credentials
        key: password
```

**Solutions**:
- HashiCorp Vault
- AWS Secrets Manager
- Kubernetes Secrets (chiffrÃ©s etcd)

---

## ğŸ¯ Exemple RÃ©el - E-commerce

### Workflow Complet

1. **Dev commit** â†’ GitHub
2. **CI/CD** â†’ Tests + Build Docker
3. **Terraform** â†’ CrÃ©e EKS + RDS + S3
4. **ArgoCD** â†’ DÃ©ploie vers K8s
5. **K8s** â†’ Orchestre 100+ Pods
6. **Prometheus** â†’ Collecte mÃ©triques
7. **Grafana** â†’ Dashboard temps rÃ©el
8. **Alert** â†’ Rollback auto si erreurs >1%

**RÃ©sultat**: Deploy 50x/jour, MTTR <10min

---

## ğŸ“š RÃ©capitulatif - Ce qu'on a Couvert

### Infrastructure as Code

âœ… Ansible - Configuration management
âœ… Terraform - Infrastructure provisioning
âœ… Pattern Terraform + Ansible

### Kubernetes

âœ… Architecture Control Plane/Workers
âœ… Pods, Deployments, Services
âœ… K8s vs Docker Compose

---

## ğŸ“š RÃ©capitulatif (suite)

### Monitoring & ObservabilitÃ©

âœ… 3 Piliers: Metrics, Logs, Traces
âœ… Prometheus + Grafana
âœ… Stack LGTM (Loki, Grafana, Tempo, Mimir)
âœ… SLI/SLO/SLA et Error Budgets
âœ… Alert Fatigue et solutions

### IntÃ©gration DevOps

âœ… Pipeline complet Code â†’ Prod
âœ… GitOps avec ArgoCD/Flux
âœ… MÃ©triques DORA
âœ… Multi-environnements

---

## ğŸ”‘ Points ClÃ©s Ã  Retenir

### Infrastructure as Code

> "Infrastructure = Code = VersionnÃ© = TestÃ© = Reproductible"

### Kubernetes

> "Docker pour dev local, Kubernetes pour production"

### ObservabilitÃ©

> "On ne peut amÃ©liorer que ce qu'on mesure"

### DevOps

> "Automatiser tout ce qui est rÃ©pÃ©table"

---

## ğŸš€ Aller Plus Loin

### Pour Approfondir

**Ansible**:
- Ansible Galaxy: galaxy.ansible.com
- AWX: Interface web gratuite

**Terraform**:
- Registry: registry.terraform.io
- Terraform Cloud: app.terraform.io

**Kubernetes**:
- Minikube: Local K8s pour apprendre
- k3s: K8s lÃ©ger pour IoT/Edge

**Monitoring**:
- Prometheus: prometheus.io
- Grafana Labs: grafana.com

---

## ğŸ“– Ressources RecommandÃ©es

### Documentation Officielle

- ğŸ“˜ **Kubernetes**: kubernetes.io/docs
- ğŸ“• **Terraform**: developer.hashicorp.com/terraform
- ğŸ“— **Ansible**: docs.ansible.com
- ğŸ“™ **Prometheus**: prometheus.io/docs

### Livres

- ğŸ“– **Site Reliability Engineering** (Google)
- ğŸ“– **Kubernetes Up & Running**
- ğŸ“– **Terraform: Up & Running**

### CommunautÃ©s

- r/devops, r/kubernetes (Reddit)
- CNCF Slack, Kubernetes Slack

---

## ğŸ¯ Prochaines Ã‰tapes

### AprÃ¨s ce Module

1. âœ… **TP pratiques** Ã  venir:
   - TP Git/GitFlow (Module 3)
   - TP GitHub Actions (Module 5)
   - TP Docker (Module 7)

2. ğŸ“ **QCM final**: Ã‰valuation Modules 2-8

3. ğŸ’¼ **Projet professionnel**:
   - Appliquer DevOps dans votre contexte
   - Identifier processus Ã  automatiser

---

## â“ Questions?

### Module 07 - Autres Outils DevOps

**ThÃ¨mes couverts**:
- Infrastructure as Code (Ansible, Terraform)
- Kubernetes (Orchestration)
- Monitoring & ObservabilitÃ© (Prometheus, Grafana)
- IntÃ©gration DevOps complÃ¨te

**Contact**: Fabrice Claeys
**Email**: fabrice@example.com

---

<!-- _class: lead -->

# Merci!

**Module 07 terminÃ©**

*Pause de 15 minutes*

*Retour pour Module 08: Conclusion*

M2 ESTD - Initiation DevOps | ForEach Academy
